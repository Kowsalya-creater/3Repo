{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#requests beautifulsoup4 \n",
    "# this basically reuest and and get all the html page data including all the tags and it will recieve it\n",
    "#this data will be given to  beautifulsoup and get the text from that\n",
    "%pip install beautifulsoup4 requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#writing the following im function so that this block of code can be reused again n again\n",
    "def web_scraper(url, filename):\n",
    "    #header for website like imdb wr REQUEST doent work to extract data in html format\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    website_data = requests.get(url, headers = header)\n",
    "\n",
    "    '''website_data.status_code\n",
    "\n",
    "    #200 given in output cell is successful responses - HTTP response status codes'''\n",
    "\n",
    "    # will write a if condition - if the responses is successful(#200), we will pass it to beautifulsoup\n",
    "\n",
    "    if website_data.status_code == 200:\n",
    "        website_content = BeautifulSoup(website_data.content, 'html.parser') # meaning the content is from a html page\n",
    "\n",
    "        # extract all the paragraphs\n",
    "        paragraphs = website_content.find_all('p')\n",
    "\n",
    "        # need to store these extracted paragraphs somewhere\n",
    "        # store in txt file\n",
    "\n",
    "        with open (f'{filename}.txt', mode = 'w', encoding = 'utf-8') as file:\n",
    "            # for loop to extract the text content without <p> paragraph tag into the text file\n",
    "            for para in paragraphs:\n",
    "                text = para.getText()\n",
    "                file.write(text) # text file is created n the content is extracted and stored in text format\n",
    "        print(f'The web scarping is completed and the file is created with name {filename}')\n",
    "\n",
    "    else:\n",
    "        print(f\"The response is error with status code {website_data.status_code}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs # prints paragraphs with paragraph tag <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs[10].getText() # will print just the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The web scarping is completed and the file is created with name Machine_Learning\n",
      "The web scarping is completed and the file is created with name India\n"
     ]
    }
   ],
   "source": [
    "# request to get the data from this site in html format\n",
    "url = \"https://en.wikipedia.org/wiki/Machine_learning\"\n",
    "url1 = \"https://en.wikipedia.org/wiki/India\"\n",
    "\n",
    "web_scraper(url,'Machine_Learning')\n",
    "web_scraper(url1,'India')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The web scarping is completed and the file is created with name Mission Impossible\n"
     ]
    }
   ],
   "source": [
    "imdb = \"https://www.imdb.com/title/tt9603208/?ref_=vp_vi_tt\"\n",
    "web_scraper(imdb, 'Mission Impossible')\n",
    "# this will show response error with status code 403\n",
    "#coz some website will not allow REQUESTS to get the data from the site in htmp form\n",
    "# for this we use 'browser header for request library' - serach this in google n copy from stackoverflow \n",
    "# refer to HEADER in our func - web_scraping \n",
    "# after including header in webscraping and passing it as parameters in website_data it will not show error response #403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
